{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MNIST Neural Network Training Notebook\n",
    "\n",
    "This notebook demonstrates how to build, train, and evaluate a neural network for MNIST digit recognition from scratch. The code is modular, well-commented, and includes visualization of the training progress.\n"
   ],
   "id": "948f67442003954f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T00:46:03.631510Z",
     "start_time": "2025-04-07T00:46:02.913618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adjust the Python path to include the project root if necessary\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import dataset module and neural network components\n",
    "from src.dataset.dataset import load_and_preprocess_mnist\n",
    "from src.neuralnet.network import NeuralNetwork\n",
    "from src.neuralnet.layers import Dense\n",
    "from src.neuralnet.activations import relu, relu_derivative, softmax\n",
    "from src.neuralnet.losses import cross_entropy_loss, cross_entropy_loss_derivative\n",
    "from src.neuralnet.utils import one_hot_encode\n"
   ],
   "id": "a43c8376fc918084",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load and Preprocess the MNIST Dataset\n",
    "\n",
    "We load the raw MNIST data, preprocess the images (normalization and reshaping), and split the data into training, validation, and test sets. Labels are one-hot encoded for use with the cross-entropy loss.\n"
   ],
   "id": "46fd7534e840e161"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-07T00:46:21.695188Z",
     "start_time": "2025-04-07T00:46:21.316889Z"
    }
   },
   "source": [
    "# Define the data directory (adjust the path as needed)\n",
    "data_dir = os.path.join(os.getcwd(), \"../data/mnist\")\n",
    "\n",
    "# Load dataset using the provided module\n",
    "train_images_all, train_labels_all, test_images, test_labels = load_and_preprocess_mnist(data_dir)\n",
    "\n",
    "# Split training data into training and validation sets (90% training, 10% validation)\n",
    "split_index = int(0.9 * train_images_all.shape[0])\n",
    "train_images = train_images_all[:split_index]\n",
    "train_labels = train_labels_all[:split_index]\n",
    "val_images = train_images_all[split_index:]\n",
    "val_labels = train_labels_all[split_index:]\n",
    "\n",
    "# One-hot encode the labels for training, validation, and test sets\n",
    "num_classes = 10\n",
    "train_labels_encoded = one_hot_encode(train_labels, num_classes)\n",
    "val_labels_encoded = one_hot_encode(val_labels, num_classes)\n",
    "test_labels_encoded = one_hot_encode(test_labels, num_classes)\n",
    "\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Validation images shape:\", val_images.shape)\n",
    "print(\"Test images shape:\", test_images.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (54000, 784)\n",
      "Validation images shape: (6000, 784)\n",
      "Test images shape: (10000, 784)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "56f1bf6d78087edd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
